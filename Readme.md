## ğŸš€ Built My Own Redis-Like In-Memory Cache in Go â€“ Hereâ€™s What I Learned! ğŸ”§ğŸ§ 

Over the last few days, Iâ€™ve been working on a Redis-inspired, lightweight **in-memory caching service written in Go**, aiming to benchmark its performance, implement best concurrency practices, and modularize it for service-level use. Here's a breakdown of my journey:

---

### ğŸ› ï¸ **What I Built**

A custom **Go-based in-memory key-value store** supporting:

- Basic `Set`, `Get`, `Update`, and `Delete` operations
    
- TTL (Time-To-Live) support with a background cleanup goroutine
    
- Safe concurrency using `sync.RWMutex`
    
- Modular design to support **plug-and-play cache clients**
    

---

### âš™ï¸ **Key Technical Features**

- ğŸ” **TTL Expiry**: Automatic deletion of expired keys every second.
    
- ğŸ”’ **RWMutex over Mutex**: Replaced `sync.Mutex` with `sync.RWMutex` to reduce contention in read-heavy workloads.
    
- âš¡ **Benchmarking**: Used `go test -bench` to validate optimizations.
    
- ğŸ“¦ **Dependency Injection**: Designed to swap the backend (`inmemcache`, `redis`, etc.) with minimal code changes.
    
- âœ… **Graceful Shutdown**: Catches `SIGINT/SIGTERM` to cleanly stop background goroutines.
    
- ğŸ§ª **Microservice-Ready**: Built as a package usable by any Go service â€“ supports both standalone mode and embedding.
    

---

### ğŸ“Š **Performance Benchmark**

Tested on: `Intel i5-8300H`, Go 1.22, Windows/Linux

#### ğŸ”¹ `inmemcache` (without RWMutex):

```
BenchmarkSet-8     2221554      515.3 ns/op     222 B/op    4 allocs/op
BenchmarkGet-8     4211239      335.7 ns/op      23 B/op    1 allocs/op
BenchmarkUpdate-8  4299273      319.3 ns/op      23 B/op    1 allocs/op

```

#### ğŸ”¸ `rw_memcache` (with RWMutex):

```
BenchmarkSet-8     2216912      520.2 ns/op     222 B/op    4 allocs/op
BenchmarkGet-8     4372797      296.2 ns/op      23 B/op    1 allocs/op âœ…
BenchmarkUpdate-8  3985664      328.0 ns/op      23 B/op    1 allocs/op
```

âœ… **RWMutex showed ~11% improvement on Get() performance**, ideal for read-heavy use cases!

---

### ğŸ¤” **Lessons Learned**

- RWMutex helps only when you have high read concurrency. Set/Update, being write locks, see little gain.
    
- Pooling or batching operations might help optimize write paths further.
    
- `sync.Map` is good for dynamic workloads but sacrifices type safety.
    
- Graceful shutdown handling is essential even for internal services.
    

---

### ğŸ”„ **Next Steps**

- Add LRU/ARC eviction strategies
    
- Support for persistence (snapshot or AOF-like)
    
- gRPC or HTTP API wrapper for remote usage
    
- Extend with pluggable backends (Redis, Memcached, etc.)
    
